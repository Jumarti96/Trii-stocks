{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e533b33-2e59-4780-a1af-ddb0947a828e",
   "metadata": {},
   "source": [
    "### **Load libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a203e6b-1506-495b-95b4-b66f8a1702e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import risk_kit as rk\n",
    "import importlib\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.tsa.stattools as sts\n",
    "from statsmodels.tsa.api import VAR\n",
    "from mgarch import mgarch\n",
    "\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6be3bc1-18d6-4abc-8eba-7c090be93397",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62329e34-5b27-426a-b978-2fd71f7eed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146df3f-849b-4af7-b1c6-b4cf4d5467ed",
   "metadata": {},
   "source": [
    "### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d33ae6d-7b40-49e9-941d-816840e8c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = pd.read_csv('selected_stocks_rets.csv', index_col=0)\n",
    "stocks = pd.read_csv('selected_stocks_stocks.csv', index_col=0)\n",
    "\n",
    "rets.index = pd.to_datetime(rets.index).to_period('W')\n",
    "stocks.index = pd.to_datetime(stocks.index).to_period('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7606a027-a8e1-4f6c-867f-2de8dec352d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of periods per year for all calculations\n",
    "# 252 is an approximation for daily\n",
    "# 54 for weekly\n",
    "# 12 for monthly\n",
    "periods_per_year = 54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f4097-56a6-43ba-ac1d-33ca64dbc769",
   "metadata": {},
   "source": [
    "# **Estimation of future Moving Average Returns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083d783-0dcb-45a9-bf8f-cf0064521ff2",
   "metadata": {},
   "source": [
    "### **Analysis of stationarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c86a25-f6d4-4ede-bfd2-8334a0381bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Dickey Fuller Test p-value for non-stationarity of level BCOLOMBIA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level BOGOTA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level BVC.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CELSIA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CNEC.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CORFICOLCF.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level ECOPETROL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level ENKA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GEB.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GRUBOLIVAR.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GRUPOARGOS.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GRUPOAVAL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GRUPOSURA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level HCOLSEL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level ICOLCAP.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level ISA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level MINEROS.CL series: 0.0141\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level NUTRESA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFAVAL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFBCOLOM.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFCORFICOL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFDAVVNDA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFGRUPOARG.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFGRUPSURA.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PROMIGAS.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level TERPEL.CL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level AAPL series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level BRK-B series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CBU7.L series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CENCOSUD.SN series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level CHILE.SN series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level EIMI.L series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level F series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level FALABELLA.SN series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level GE series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level JNJ series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level LQDA series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level NKE series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level PFE series: 0.0\n",
      "Augmented Dickey Fuller Test p-value for non-stationarity of level UBER series: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Analysis of stationarity for the whole series\n",
    "for stock in rets.columns:\n",
    "    print(f'Augmented Dickey Fuller Test p-value for non-stationarity of level {stock} series: {round(adfuller(rets[stock])[1], 4)}')\n",
    "\n",
    "# All return series are stationary, however, differentiating by first order seems to result in better models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56e283-677e-4ea3-a670-eaa5332564ca",
   "metadata": {},
   "source": [
    "### **Method 1. VAR bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9c4eeb-1dab-4b0d-95e5-e9f75b4f6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1st order integration for the returns series\n",
    "rets_integrated = (rets - rets.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78c95ea-142c-43d1-80df-88ce3e20ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list = list(rets.columns.values) # List of all available stock symbols\n",
    "n_iterations = 2000 # The number of iterations of VAR models to perform\n",
    "set_size = 10 # Number of symbols modeled in each iteration\n",
    "periods_to_forecast = 4 # Number of periods to forecast\n",
    "\n",
    "# Initialize an empty list of sets of stock symbols\n",
    "iterations_symbols = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # For each iteration of the model, select a random set of 'set_size' stock symbols\n",
    "    iterations_symbols.append(random.sample(symbols_list, set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6323b73e-2f2c-4e4e-8aa1-a2ef8940e043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subset_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m {symbol: {} \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbols_list}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, symbols_selection \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterations_symbols):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# In each iteration, generate a dataset with the stocks selected for the iteration only\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#subset_df = rets_integrated[symbols_selection]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Compare the IC (Information Criteria) scores for VAR models of various number of lags to select the ideal number of lags\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     varmod \u001b[38;5;241m=\u001b[39m VAR(\u001b[43msubset_df\u001b[49m)\n\u001b[0;32m     10\u001b[0m     lag_sel \u001b[38;5;241m=\u001b[39m varmod\u001b[38;5;241m.\u001b[39mselect_order(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Select the best number of lags according to the AIC criterion\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subset_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary of dictionaries where the results of each iteration will be stored\n",
    "prediction_results = {symbol: {} for symbol in symbols_list}\n",
    "\n",
    "for i, symbols_selection in enumerate(iterations_symbols):\n",
    "    # In each iteration, generate a dataset with the stocks selected for the iteration only\n",
    "    #subset_df = rets_integrated[symbols_selection]\n",
    "    \n",
    "    # Compare the IC (Information Criteria) scores for VAR models of various number of lags to select the ideal number of lags\n",
    "    varmod = VAR(subset_df)\n",
    "    lag_sel = varmod.select_order(10)\n",
    "    \n",
    "    # Select the best number of lags according to the AIC criterion\n",
    "    n_lags = lag_sel.aic\n",
    "    print(f'Iteration {i}, ideal_n_lags: {n_lags}')\n",
    "    \n",
    "    # Fit the model for the iteration\n",
    "    var_model = VAR(subset_df).fit(maxlags=n_lags, trend='c')\n",
    "\n",
    "    # Predict the following 'periods_to_forecast' periods\n",
    "    predictions = var_model.forecast(subset_df.iloc[-n_lags:].values, periods_to_forecast)\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "\n",
    "    # Append the predicted values to the 'prediction_results' dictionary\n",
    "    for l in predictions:\n",
    "        prediction_results[symbols_selection[l]][i] = predictions[l]\n",
    "    print(f'Iteration {i+1} finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77721207-1009-4283-a93f-7df9f35dbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Copy the 'prediction_results' dictionary to invert the integration of the copy and set the index for predicted dates\n",
    "prediction_results_processed = prediction_results.copy()\n",
    "for symbol in prediction_results:\n",
    "    # For each stock in 'prediction_results', convert the predictions into a dataframe\n",
    "    pred_df = pd.DataFrame(prediction_results[symbol])\n",
    "\n",
    "    # Get the average predictions for each day\n",
    "    pred_series = pred_df.mean(axis=1)\n",
    "\n",
    "    # Invert the integration by taking the last actual returns and add it to the predictions, then do a cumulative sum\n",
    "    pred_series = rets[symbol][-1] + pred_series.cumsum()\n",
    "    \n",
    "    # Generate an index for the future dates\n",
    "    #future_dates = pd.date_range(start=rets.index.max().to_timestamp() + pd.Timedelta(value=1, unit='d'), periods=periods_to_forecast)\n",
    "    future_dates = pd.date_range(start=rets.index.max().to_timestamp() + pd.Timedelta(value=7, unit='d'), periods=periods_to_forecast, freq='W-SUN').to_period('W') # Weekly\n",
    "    pred_series.index = future_dates\n",
    "    \n",
    "    # Add the series of average predicted returns for the stock to the 'prediction_results_processed' dictionary\n",
    "    prediction_results_processed[symbol] = pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fadda-cfb4-404c-892b-96b26d92ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions of any stock\n",
    "symbol = 'PFGRUPSURA.CL'\n",
    "concat_df = pd.concat([rets[symbol][-50:], pd.DataFrame(prediction_results_processed[symbol], columns=[symbol])], axis=1)\n",
    "\n",
    "concat_df.plot()\n",
    "#prediction_results_processed[symbol].plot()\n",
    "plt.grid(alpha=.4)\n",
    "plt.title(symbol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e7e40-371c-440c-8899-fe6bdd90b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the exptected annual returns for each stock\n",
    "# Initialize an empty dictionary where the returns will be stored\n",
    "expected_annualized_rets = {}\n",
    "\n",
    "for symbol in prediction_results_processed:\n",
    "    # Calculate the weighted average returns from the predictions and then annualize them\n",
    "    # Uncomment the method of weighting for the averaging and annualization of the returns\n",
    "    \n",
    "    ### Raw predicted returns annualized\n",
    "    # expected_annualized_returns = ((prediction_results_processed[symbol] + 1).prod()**(1/len(prediction_results_processed[symbol])))**(periods_per_year) - 1\n",
    "    \n",
    "    ### Linearly decaying weighted returns annualized\n",
    "    # weight_indexes = np.array([i+1 for i in range(periods_to_forecast)])\n",
    "    # linear_decay_w = (periods_to_forecast - weight_indexes + 1)/weight_indexes.sum()\n",
    "    # expected_annualized_returns = (1 + np.sum(prediction_results_processed[symbol]*linear_decay_w))**periods_per_year - 1\n",
    "\n",
    "    ### Exponentially decaying weighted returns annualized\n",
    "    weight_indexes = np.array([i+1 for i in range(periods_to_forecast)])\n",
    "    lambda_ = 0.2\n",
    "    exponential_decay_w = np.exp(-lambda_*weight_indexes)/np.exp(-lambda_*weight_indexes).sum()\n",
    "    expected_annualized_returns = (1 + np.sum(prediction_results_processed[symbol]*exponential_decay_w))**periods_per_year - 1\n",
    "\n",
    "    expected_annualized_rets[symbol] = expected_annualized_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340a220-71b1-468f-af50-837e7646c427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(expected_annualized_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ff14e-e89c-4079-a137-bbe1fe71d870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare with the expected returns calculated from historical returns\n",
    "rk.summary_stats(rets.iloc[-108:], periods_per_year=periods_per_year)['Annualized Return']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ada6e6-2050-41d2-9050-45a758b759fa",
   "metadata": {},
   "source": [
    "### **Covariance matrix estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab7f87-8c85-4b23-bec2-d4dee111f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Simple long-term covariance\n",
    "covmat = rets.cov()\n",
    "returns = summary_stats['Annualized Return']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e86cc-c987-4a2f-a0f8-017942368988",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = rk.summary_stats(rets, periods_per_year=periods_per_year, riskfree_rate=0)\n",
    "returns = summary_stats['Annualized Return']\n",
    "\n",
    "# Recent covariance prediction based on recent days with GARCH model\n",
    "vol = mgarch('t')\n",
    "vol.fit(rets)\n",
    "nperiods = 4\n",
    "covmat = vol.predict(nperiods)\n",
    "covmat = pd.DataFrame(data=covmat['cov'], index=returns.index, columns=returns.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cc938-30bd-468f-8cfc-d402454d10b0",
   "metadata": {},
   "source": [
    "### **Export predicted returns and covariance matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacde599-f711-49b7-93c7-ab628d6942fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(expected_annualized_rets).to_csv('expected_returns.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96418a-8ea1-4f45-b89d-c7802bf3b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat.to_csv('expected_covmat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
